# Recurrent Neural Networks (RNNs)
`Recurrent neural networks(RNNs)` are a powerful and robust type of neural network, and belong to the most promising algorithms in use because it is the only one with an internal memory.

Like many other deep learning algorithms, recurrent neural networks are relatively old. They were initially created in the 1980’s, but only in recent years have we seen their true potential. An increase in computational power along with the the massive amounts of data that we now have to work with, and the invention of long short-term memory (LSTM) in the 1990s, has really brought RNNs to the foreground.

Because of their internal memory, RNN’s can remember important things about the input they received, which allows them to be very precise in predicting what’s coming next. This is why they're the preferred algorithm for sequential data like time series, speech, text, financial data, audio, video, weather and much more. Recurrent neural networks can form a much deeper understanding of a sequence and its context compared to other algorithms.

## Subsets of `Recurrent Neural Networks`:
##### best way is to learn is from `TOP` to `BOTTOM`.
- [`Recurrent Neural Network`](./recurrent_neural_network)
- [`Long Short Term Memory`](./long_short_term_memory)
- [`Gated Recurrent Unit`](./gated_recurrent_unit)

<p align="center">
  <img src="https://camo.githubusercontent.com/61cd232998541a3dd8e3b72bd25035940f373c1a4bd745fbe68e6424345adcb2/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f62347375732e6a7067" width="500px">
</p>
<p align="center">
  <img src="https://miro.medium.com/max/3378/1*LNVsKOvftmxCTrM5vJOCEA.png" width="500px">
</p>
<p align="center">
  <img src="http://www.wildml.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM.png" width="500px">
</p>

## Usefull Resources:
+ https://datascience-enthusiast.com/DL/Building_a_Recurrent_Neural_Network-Step_by_Step_v1.html
+ http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/
+ http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
+ https://deepmind.com/blog/article/A_new_model_and_dataset_for_long-range_memory 
+ https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/
+ https://colah.github.io/posts/2015-08-Understanding-LSTMs/
+ https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
+ https://towardsdatascience.com/learn-how-recurrent-neural-networks-work-84e975feaaf7
+ https://karpathy.github.io/2015/05/21/rnn-effectiveness/  
+ https://cs231n.github.io/neural-networks-case-study  
+ https://towardsdatascience.com/recurrent-neural-networks-rnns-3f06d7653a85   
+ https://d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html    
+ https://datascience-enthusiast.com/DL/Building_a_Recurrent_Neural_Network-Step_by_Step_v1.html
+ https://medium.com/@jianqiangma/all-about-recurrent-neural-networks-9e5ae2936f6e